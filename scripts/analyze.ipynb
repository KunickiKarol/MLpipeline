{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18370ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import dvc.api\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "params = dvc.api.params_show()\n",
    "\n",
    "start_file = params['processing']['target_file']\n",
    "\n",
    "\n",
    "df_all = pd.read_json(start_file, lines=True)\n",
    "df_all['reviewTextLength'] = df_all['reviewText'].astype(str).apply(len)\n",
    "df_all['numbers_amount'] = df_all['reviewText'].str.count(r'\\d+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bae76cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Liczba klas:', df_all['overall'].nunique())\n",
    "class_counts = df_all['overall'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ea09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = df_all['overall'].max()\n",
    "min_value = df_all['overall'].min()\n",
    "print('Skala Overall od', min_value,'do', max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902bf47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71791fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f052b14",
   "metadata": {},
   "source": [
    "Atrybuty verified , reviewerId, asin, reviewerName, data_origin (łącznie 5) są to zmienna kategoryczna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9975ac5",
   "metadata": {},
   "source": [
    "Atrybuty reviewTime, unixReviewTime, vote, reviewTextLength, numbers_amount (łacznie 5) są to zmienna numeryczne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9406f9",
   "metadata": {},
   "source": [
    "Oprócz tego mamy adres URL (image), z którego może zostać pobrany obraz o różnym rozmiarze. Zdjęcia zawierają zdjęcia produktu od recenzującego."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e5ffe8",
   "metadata": {},
   "source": [
    "Dodatokw atrybut style przechowuje słownik mogący rozbudować atrybuty jednak wynikałoby z tego pojawienie się wielu NaN, oraz trudno porównać rozmiar szamponu i ubrania\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f5b854",
   "metadata": {},
   "source": [
    "Zmienna wyjściowa można interpretować jako zmienną numeryczną co może pomóc w szukaniu korelacji jednak nie jest to preferowane. Jest to zmienna dyskretna, która może przyjąć jedną z kilku wartości/ kategori. Ludzie nie myślą o produkcie 2/5 jako o dwa razy gorszym od 4/5. Ludzie mają wyuczone pewne interpretacje ocen w typowych skaklach oceniania (1-5, 1-10), które interpretują raczej w sposób opisowy. W jakijś książce czytałem, że przeskalowanie takich skal na dziwne skale np. od 47-73 całkowicie zaburzało postrzeganie oceny. Zaczęto otrzymywać odmienne rozkłady etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a7cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_na_counts = df_all.isna().sum() / len(df_all) * 100\n",
    "\n",
    "percent_na_counts = percent_na_counts.sort_values(ascending=False)\n",
    "print(\"procent brakujących wartośći\")\n",
    "print(percent_na_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e114a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[df_all['vote'] == '0'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8634b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[df_all['vote'] == '1'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.to_numeric(df_all['vote'], errors='coerce') < 0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8013d4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dopiero teraz isteniją rekordy z vote\n",
    "df_all.loc[df_all['vote'] == '2'].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b740e2c0",
   "metadata": {},
   "source": [
    "Obrazki są dołączone tylko do 5% rekordów. Dodatkowym pytaniem jest ile z tych linków jest działających <br>\n",
    "Tylko 30% rekordów posiada \"vote\" możliwe, że, gdy vote = 0 było jednoznaczne z wpisaniem NaN, ponieważ brakuje wartośći 0. Brakuje jednak także wartośći 1, które zapewne też byłby liczne co utrudnia potwierdzenie tej hipotezy <br> Wydaje się niemożliwym uzupełnienie braków reviewText. Na szczęśnie jest ich niewiele. Można byłoby skupić się na badaniu summary, ponieważ jest ich więcej nie zawierają jednak tyle potencjalnych informacji. <br>\n",
    "Braki w numbers_amount wynikają z braków w reviewText <br>\n",
    "Isteniją braki w reviewerName jednka teoretycznie powinna być funkcja 1-1, która zastąpiłaby je reviewerID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4501b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_tmp = df_all.drop('style', axis=1)\n",
    "df_all_tmp = df_all_tmp.drop('image', axis=1)\n",
    "print(\"Ogólnie jest duplikatów:\", round((len(df_all_tmp) - len(df_all_tmp.drop_duplicates()))/len(df_all_tmp), 1), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191fca1c",
   "metadata": {},
   "source": [
    "Możliwe, że pojawiają się obrazki jednym z dwóch duplikatów, albo dodatkowe informacje w style. Wymagalo dalszego zbadania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd4626",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['overall', 'verified', 'unixReviewTime', 'reviewTextLength', 'numbers_amount', 'vote']\n",
    "df_all_tmp['vote'] = df_all_tmp['vote'].str.replace(',', '.').astype(float)\n",
    "df_all_numeric = df_all_tmp[selected_columns]\n",
    "df_all_numeric = df_all_numeric.drop_duplicates()\n",
    "corr = df_all_numeric.corr(numeric_only=False)\n",
    "\n",
    "sns.heatmap(corr, label=True, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dbe52a",
   "metadata": {},
   "source": [
    "Wydaj 3 największe korelacje: <br>\n",
    "numbers_amount:reviewTextLenght - wydaje się logicznym, że tym dłuższy tekst tym więcej liczb tam będzie <br>\n",
    "verified:unixReviewTime -  wydaje się logicznym, że tym starsza ocena tym większa szansa na weryfikację. Tutaj jednka ty więszky timeStamp tym większa szansa na weryfikacje co może świadczyć, że dopiero od niedawna zaczęto weryfikować i stare oceny nie są weryfikowane już <br>\n",
    "verified:reviewTextLength - chętniej są weryfikowane krótkie teksty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec2e9ee",
   "metadata": {},
   "source": [
    "Overall nie ma wysokiej korelacji z jakąkolwiek zmienną. Największa korelacja overall:verified może świadczyć, że częściej weryfikowane są wyższe oceny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc634bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize(df):\n",
    "    return StandardScaler().fit_transform(df.iloc[:,0:-1].values), df['overall'].values, df.columns\n",
    "\n",
    "df_all_numeric = df_all_numeric.drop_duplicates()\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "df_all_numeric = pd.DataFrame(imputer.fit_transform(df_all_numeric),columns = df_all_numeric.columns)\n",
    "data_all_numeric_std = standarize(df_all_numeric)\n",
    "model = PCA(n_components=2)\n",
    "df_all_numeric_std = data_all_numeric_std[0]\n",
    "Y_pca = model.fit_transform(df_all_numeric_std)\n",
    "df_pca = pd.DataFrame(Y_pca, columns=('PCA1', \"PCA2\"))\n",
    "df_pca['class'] = data_all_numeric_std[1]\n",
    "sns.scatterplot(x=df_pca['PCA1'], y=df_pca['PCA2'], hue=df_pca['class'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7a2b5a",
   "metadata": {},
   "source": [
    "Same zmienne numeryczne, posiadają  pewien potencjał widać wyraźnie, że dla dwóch komponentów PCA można już rozróźniać dobre i złe oceny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa29ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = PCA().fit(df_all_numeric_std)\n",
    "sns.lineplot(data=np.cumsum(model_2.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aab3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from collections import Counter\n",
    "nltk.download('stopwords')\n",
    "text_column = df_all['reviewText']\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "text_column = text_column.str.lower().str.replace('[{}]'.format(string.punctuation), '')\n",
    "text_column = text_column.apply(lambda x: ' '.join([word for word in str(x).split() if word not in stop_words]))\n",
    "\n",
    "words = ' '.join(text_column).split()\n",
    "word_freq = Counter(words)\n",
    "sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "top_words = sorted_words[:20]\n",
    "print(top_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc702672",
   "metadata": {},
   "source": [
    "Łatwo rozpoznać słowa mogące świadczyć o sentymencie \"great\", 'well\", \"good\" możliwe, żę \"like\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1508cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_all[df_all['overall'] == 1]\n",
    "df2 = df_all[df_all['overall'] == 2]\n",
    "df3 = df_all[df_all['overall'] == 3]\n",
    "df4 = df_all[df_all['overall'] == 4]\n",
    "df5 = df_all[df_all['overall'] == 5]\n",
    "\n",
    "def word_frequency(df):\n",
    "    text_column = df['reviewText']\n",
    "    text_column = text_column.str.lower().str.replace('[{}]'.format(string.punctuation), '')\n",
    "    text_column = text_column.apply(lambda x: ' '.join([word for word in str(x).split() if word not in stop_words]))\n",
    "    words = ' '.join(text_column).split()\n",
    "    word_freq = Counter(words)\n",
    "    return word_freq\n",
    "\n",
    "wf1 = word_frequency(df1)\n",
    "wf2 = word_frequency(df2)\n",
    "wf3 = word_frequency(df3)\n",
    "wf4 = word_frequency(df4)\n",
    "wf5 = word_frequency(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08e1f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_words(word_freq, n):\n",
    "    sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_words = [w[0] for w in sorted_words[:n]]\n",
    "    return set(top_words)\n",
    "\n",
    "top_n = 30\n",
    "overall_words = {}\n",
    "overall_words[1] = top_words(wf1, top_n)\n",
    "overall_words[2] = top_words(wf2, top_n)\n",
    "overall_words[3] = top_words(wf3, top_n)\n",
    "overall_words[4] = top_words(wf4, top_n)\n",
    "overall_words[5] = top_words(wf5, top_n)\n",
    "\n",
    "print(\"Specyficzne słowa z top 30 najczęstszych dla najgorszch ocen\")\n",
    "print(overall_words[1] - overall_words[3] - overall_words[4] - overall_words[5])\n",
    "print(\"Specyficzne słowa z top 30 najczęstszych dla najlpeszych ocen\")\n",
    "print(overall_words[5] - overall_words[3] - overall_words[2] - overall_words[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2894afb5",
   "metadata": {},
   "source": [
    "Widać dużo jednoznacznie dobrych przymiotników przy ocenach = 5 <br>\n",
    "Przy ocench = 1 widać, że istnieją problemy w systemem microsofut vista lub 7 i w zmianach oprogramowania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6e825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = df_all['reviewText'].astype(str).apply(len)\n",
    "print(\"Całkowita długość tekstu: \", text_length.mean(), 'znaków')\n",
    "print(\"Średnia długość tekstu: \", text_length.mean(), 'znaków')\n",
    "print(\"Maksymalna długość tekstu: \", text_length.max(), 'znaków')\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('punkt')\n",
    "\n",
    "text = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')\n",
    "words = nltk.word_tokenize(text)\n",
    "non_unique_words = len(words) - len(set(words))\n",
    "\n",
    "print(\"Co stanowi \", round(text_length.max()/non_unique_words*100, 1), '% ksiązki \"Moby Dick\"')\n",
    "print(\"Minimalna długość tekstu: \", text_length.min(), 'znaków')\n",
    "# w sumie mogłęm wykorzystać kolumnę którą stworzyłem:p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742d076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "words = text_column.str.cat(sep=' ').split()\n",
    "word_freq = collections.Counter(words)\n",
    "\n",
    "print(\"Liczba unikalnych słów: \", len(word_freq))\n",
    "print(\"W Panu Tadeuszu jest 2x więcej unikalnych słów\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7874cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_idx = df_all['reviewText'].str.len().idxmax()\n",
    "max_length_row = df_all.loc[max_length_idx]\n",
    "\n",
    "print(\"Wiersz z maksymalną długością tekstu: \")\n",
    "print(max_length_row['reviewText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22299c3d",
   "metadata": {},
   "source": [
    "Należy przeprowadzić dogłebną anlizę reviewText oraz summary, mogą zawierać wiele dodatkowych przydatnych inforamcji pomagających ustalić overall. Należałoby również spróbować zamieć datę na zmienną kategoryczną mówiącą np. o okresach w roku (przed Świętami, wakacje, początek roku szkolnego) może pomogłoby to znaleźć powiązania. Także samo sprawdzenie, czy obecność zdjęcia/ ich ilość jak wpływa na overall. Połączenie tego z danymi numerycznymi może pomóc stowrzyć model klasyfikiacji o wysokim stopniu accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
